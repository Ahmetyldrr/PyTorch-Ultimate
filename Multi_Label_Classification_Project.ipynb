{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1R2UbqnzvP62t_PP8KezcGo4N25QM8frk",
      "authorship_tag": "ABX9TyPo6k/TW3EQKWjIvmTIunah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmetyldrr/PyTorch-Ultimate/blob/main/Multi_Label_Classification_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Gerekli paketlerin import edilmesi\n",
        "\n",
        "## CHAPGPT\n",
        "#--------------------------------------\n",
        "# - sklearn'den make_multilabel_classification: Çok etiketli sınıflandırma için sentetik veri oluşturur.\n",
        "# - train_test_split: Veriyi eğitim ve test olarak böler.\n",
        "# - accuracy_score: Sınıflandırma doğruluk skorunu hesaplar.\n",
        "# - PyTorch'un temel bileşenleri: tensör, modül (nn), veri yüklemek için DataLoader, Dataset vb.\n",
        "# - seaborn ve collections: Veri görselleştirme (kaynak kodun sonuna doğru scatterplot) ve sayım işlemleri için kullanılır.\n",
        "\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# %% Veri oluşturma (data prep)\n",
        "#--------------------------------\n",
        "# make_multilabel_classification fonksiyonu ile sahte (synthetic) çok etiketli bir veri kümesi oluşturuyoruz.\n",
        "# Bu veri kümesinde:\n",
        "#   - n_samples=100: 100 örnek (örnek sayısı)\n",
        "#   - n_features=10: 10 öz nitelik (feature)\n",
        "#   - n_classes=3: 3 farklı etiket\n",
        "#   - n_labels=2: Her örnekte ortalama 2 etiketin aktif olması beklenir.\n",
        "# Üretilen X, y ikililerinde X, girdi özelliklerini; y ise (örneğin [1, 0, 1] gibi) etiket vektörlerini barındırır.\n",
        "\n",
        "X, y = make_multilabel_classification(n_samples=100,\n",
        "                                      n_features=10,\n",
        "                                      n_classes=3,\n",
        "                                      n_labels=2)\n",
        "\n",
        "# Üretilen numpy dizilerini PyTorch tensörlerine dönüştürüyoruz.\n",
        "X_torch = torch.FloatTensor(X)\n",
        "y_torch = torch.FloatTensor(y)\n",
        "\n",
        "# Veriyi eğitim ve test olarak bölerken, test boyutu %20 olarak ayarlanır.\n",
        "# X_train, X_test: Özellikler\n",
        "# y_train, y_test: Etiketler\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_torch,\n",
        "                                                    y_torch,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "\n",
        "# %% Dataset ve DataLoader tanımlanması\n",
        "#---------------------------------------\n",
        "# PyTorch'ta kendi veri setimizi, Dataset sınıfından türeterek tanımlıyoruz.\n",
        "# Bu şekilde DataLoader ile verileri kolayca kümelere (batch) ayırabilir,\n",
        "# eğitim döngüsünde bu verileri kullanabiliriz.\n",
        "\n",
        "class MultilabelDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        # X ve y, yapıcı fonksiyonda (constructor) saklanıyor\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        # Bu fonksiyon, veri setinin kaç örnek (sample) içerdiğini döndürür\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Bu fonksiyon, belirli bir index’e (idx) sahip tek bir örneğin\n",
        "        # özelliklerini (X) ve etiketlerini (y) döndürür\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "# DataLoader: Verileri batch halinde almak, shuffle yapmak ve\n",
        "# çok daha kolay veri yönetimi sağlamak amacıyla kullanılır.\n",
        "multilabel_data = MultilabelDataset(X_train, y_train)\n",
        "train_loader = DataLoader(dataset = multilabel_data, batch_size=10)\n",
        "# batch_size=10 demek, her seferinde 10 örneklik mini-batch'ler ile eğitime girileceği anlamına gelir.\n",
        "\n",
        "\n",
        "# %% Model tanımlaması\n",
        "#---------------------------------------\n",
        "# Basit bir Tam Bağlantılı (Fully Connected) sinir ağı tanımlıyoruz (MultilabelNetwork).\n",
        "# Ağı yapısı:\n",
        "# - fc1: Girdi boyutunu gizli katmana çeviren tam bağlantılı katman\n",
        "# - ReLU: Aktivasyon fonksiyonu\n",
        "# - fc2: Gizli katmandan çıkış katmanına\n",
        "# - Sigmoid: Çıkışta [0,1] arası değerler elde etmek için kullanıyoruz.\n",
        "# Çok etiketli sınıflandırmada, her bir etiketin aktif olup olmama olasılığını üretir.\n",
        "\n",
        "class MultilabelNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MultilabelNetwork, self).__init__()\n",
        "        # 1. Katman: input_size -> hidden_size\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        # Aktivasyon: ReLU\n",
        "        self.relu = nn.ReLU()\n",
        "        # 2. Katman: hidden_size -> output_size\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        # Çıkışı [0,1] aralığına map eden sigmoid aktivasyon\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # İleri yönlü geçiş (forward pass)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        # Çok etiketli tahmin için sigmoid ile skorları 0-1 arasına sıkıştırıyoruz\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Girdi boyutu (input_dim) ve çıktı boyutu (output_dim) veriyi okuyarak bulunur.\n",
        "input_dim = X_torch.shape[1]   # X'in sütun sayısı -> 10\n",
        "output_dim = y_torch.shape[1]  # y'nin sütun sayısı -> 3\n",
        "\n",
        "# Modeli belirtilen boyutlarla örnekliyoruz:\n",
        "# - input_size=10, hidden_size=20, output_size=3\n",
        "model = MultilabelNetwork(input_size=input_dim,\n",
        "                          hidden_size=20,\n",
        "                          output_size=output_dim)\n",
        "\n",
        "# model.train() metodu, modülü eğitim moduna alır. (Dropout, BatchNorm gibi katmanlar varsa etkili olur)\n",
        "model.train()\n",
        "\n",
        "\n",
        "# %% Kayıp fonksiyonu (Loss) ve Optimizasyon (Optimizer) seçimi\n",
        "#---------------------------------------------------------------\n",
        "# - BCEWithLogitsLoss: Çoklu etiketli sınıflandırmada sıkça kullanılan\n",
        "#   binary cross-entropy tabanlı bir kayıp fonksiyonudur.\n",
        "# - Adam: Popüler bir optimizasyon algoritmasıdır (momentum, adaptif öğrenme oranı vb. özellikler barındırır).\n",
        "# (Not: BCEWithLogitsLoss, modelin çıktılarına genelde sigmoid uygulaması entegre eder;\n",
        "#  fakat yukarıdaki gibi model içinde sigmoid kullandığınızda da BCE'yi kullanabilirsiniz.\n",
        "#  Tek fark 'WithLogits' öncesi tipik kullanımda sigmoid modeli kayıp fonksiyonu içinde olur.)\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# eğitim süresince takip etmek için kayıpları (loss) bir listede saklıyoruz\n",
        "losses = []\n",
        "# Aşağıda basit bir şekilde epoch sayısını 100 olarak belirledik.\n",
        "number_epochs = 100\n",
        "\n",
        "# Eğitim döngüsü\n",
        "for epoch in range(number_epochs):\n",
        "    for j, data in enumerate(train_loader):\n",
        "        # train_loader bize her seferinde 10'luk mini-batch (X, y) getiriyor\n",
        "        # data[0]: X (özellikler), data[1]: y (etiketler)\n",
        "\n",
        "        # 1. Adım: Geriye dönük hesaplamaları (gradient) sıfırlama\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. Adım: İleri geçiş (forward)\n",
        "        y_hat = model(data[0])\n",
        "\n",
        "        # 3. Adım: Kayıp (loss) hesaplama\n",
        "        # y_hat: modelin tahminleri\n",
        "        # data[1]: gerçek etiket değerleri\n",
        "        loss = loss_fn(y_hat, data[1])\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # 4. Adım: Geriye yayılım (backpropagation)\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Adım: Ağırlık güncelleme\n",
        "        optimizer.step()\n",
        "\n",
        "    # Belirli epoch'larda durum bilgisi yazdırma\n",
        "    if (epoch % 10 == 0):\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.data}\")\n",
        "\n",
        "\n",
        "# %% Kayıpları (Loss) görselleştirme\n",
        "#-------------------------------------\n",
        "# Kayıplar listesindeki değerleri bir dağılım grafiği ile (scatterplot) çizdiriyoruz.\n",
        "# alpha=0.1, noktaların biraz daha saydam olmasını sağlıyor ki yoğunluk anlaşılabilsin.\n",
        "\n",
        "sns.scatterplot(x=range(len(losses)), y=losses, alpha=0.1)\n",
        "\n",
        "\n",
        "# %% Modelin test aşaması\n",
        "#--------------------------------------\n",
        "# Eğitilmiş model ile test verisi (X_test) üzerinde tahmin yapıyoruz.\n",
        "# torch.no_grad() => Bu blok içindeyken PyTorch, grad hesaplamalarını kapatır,\n",
        "# yani tahmin sırasında ekstra hafıza kullanımı önlenir ve hız kazanılır.\n",
        "\n",
        "X_test_torch = torch.FloatTensor(X_test)\n",
        "with torch.no_grad():\n",
        "    # Modelin çıktısını .round() ile 0 veya 1'e yuvarlıyoruz\n",
        "    # Örneğin 0.7 -> 1, 0.3 -> 0 şeklinde\n",
        "    y_test_hat = model(X_test_torch).round()\n",
        "\n",
        "\n",
        "# %% Naive sınıflandırıcı (basit bir tahmin) doğruluğu\n",
        "#-------------------------------------------------------\n",
        "# Burada farklı bir bakış açısı olarak, \"en sık rastlanan etiket kombinasyonunu\" tahmin eden\n",
        "# bir tür naive (basit) yaklaşımın doğruluk oranını hesaplıyoruz.\n",
        "# y_test içindeki en sık görülen kombinasyon tespit edilir.\n",
        "# Bu combinasyonun kaç defa görüldüğü (most_common_cnt) bulunur.\n",
        "# Oradan bir yüzde doğruluk çıkar.\n",
        "\n",
        "# Her satır (örneğin [1, 1, 0]) string'e dönüştürülüyor.\n",
        "y_test_str = [str(i) for i in y_test.detach().numpy()]\n",
        "\n",
        "# Sonra bu string'ler içinde en sık rastlananı buluyoruz.\n",
        "most_common_cnt = Counter(y_test_str).most_common()[0][1]\n",
        "print(f\"Naive classifier: {most_common_cnt/len(y_test_str) * 100}%\")\n",
        "\n",
        "\n",
        "# %% Test doğruluğu hesaplama\n",
        "#-----------------------------\n",
        "# accuracy_score fonksiyonu y_test (gerçek) ve y_test_hat (tahmin) arasındaki\n",
        "# tam eşleşme yüzdesini döndürür. Çoklu etiketli bir problemde\n",
        "# \"her bir etiket vektörünün aynı olup olmadığına\" bakar.\n",
        "\n",
        "test_acc = accuracy_score(y_test, y_test_hat)\n",
        "print(f\"Test accuracy: {test_acc * 100}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94PZV5jp36zI",
        "outputId": "8f4bfa6b-466f-4b31-8ecb-6a11c8d8551b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 1, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 0],\n",
              "       [1, 1, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 1, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 1],\n",
              "       [0, 0, 0],\n",
              "       [1, 1, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 0, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 1, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 1, 1],\n",
              "       [0, 1, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [1, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 1, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 0, 0],\n",
              "       [1, 0, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 1, 1],\n",
              "       [1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}